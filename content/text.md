As AI capabilities become more powerful and widespread, we expect the growing use of AI systems to expand the existing threats, introduce new threats, and change the typical character of threats. We expect AI to be used for effective and finely targeted attacks on other AI systems. These attacks could exploit vulnerabilities in AI systems. Such attacks will be difficult to attribute.

AI (Neural Network) attribution identifies which pre-trained model was used to construct a subsequent model, e.g., via fine-tuning. This could allow intellectual property theft or malicious AI code to be traced back to its origin pre-trained model (e.g., identifying which base model a disinformation bot was derived from).

Developing AI Forensics capabilities and establishing the hardness of attribution is important for AI security. This challenge could contribute to the maturation of AI Forensics as a subfield of AI security. If Blue Teams cannot win for multiple rounds, that establishes that the attribution problem is hard much more effectively than directly trying to convince someone.
